# 타이타닉 생존 예측 분석

팀명: G15 (Option A)
팀원: 장예아 식품영양학과 zhangruiya1212@163.com
      나란 식품영양학과 956738154@qq.com
      유카 영어영문학과 dyy20030906@gmail.com


### 데이터셋 설명

타이타닉 데이터셋은 891명의 승객 정보를 담고 있으며, 각 승객에 대해 객실 등급(Pclass), 성별(Sex), 나이(Age), 요금(Fare), 동반 가족 수(SibSp, Parch), 탑승 항구(Embarked) 등 다양한 특징과 생존 여부(Survived, 0 또는 1)가 포함되어 있습니다. 이 데이터는 1912년 타이타닉 호 침몰 사고 당시 승객들의 생존 여부를 예측하는 데 사용됩니다.

### 동기(Motivation)

이 분석을 수행하는 이유는 타이타닉 사고에서 어떤 요인들이 승객의 생존에 영향을 미쳤는지 이해하고, 이를 바탕으로 생존을 정확히 예측할 수 있는 모델을 만드는 것입니다. 머신러닝 기법을 활용해 데이터를 분석하면서 중요한 특징을 도출하고, 다양한 모델을 비교하여 최적의 예측 방법을 찾고자 합니다.


### 최종 목표

분석의 최종 목표는 타이타닉 승객의 생존 여부를 정확하게 예측할 수 있는 모델을 구축하는 것입니다. 또한, 모델이 식별한 중요한 특징들을 통해 당시 생존에 결정적인 영향을 준 요인들을 확인하고, 이를 통해 데이터에 숨겨진 의미 있는 패턴과 인사이트를 도출하는 것입니다.


## 데이터 전처리

타이타닉 데이터셋은 승객 891명의 기록을 포함하고 있으며, 승객 등급(Pclass), 성별(Sex), 나이(Age), 요금(Fare) 등의 특징과 목표 변수(0 = 사망, 1 = 생존)를 가지고 있습니다. 모델링 전, 다음과 같은 여러 전처리 과정을 수행했습니다:

- **결측값 처리**: 데이터셋에는 Age(177개 결측), Cabin(687개 결측), Embarked(2개 결측) 컬럼에 결측값이 있습니다. Age는 극단값에 영향을 주지 않도록 훈련 데이터의 중앙값(median)으로 채웠습니다. Embarked(승선 항구)는 가장 빈번한 값인 'S'로 채웠습니다. Cabin은 대부분 결측이라 구체적인 값을 보간하기보다 Cabin이 있는지 여부를 나타내는 이진 특성 HasCabin을 새로 만들어 Cabin이 존재하면 1, 없으면 0으로 표시하고 원본 Cabin 컬럼은 제거했습니다.

- **특성 엔지니어링**: 동반 가족 규모를 나타내는 FamilySize를 형제/배우자 수(SibSp)와 부모/자녀 수(Parch)를 합쳐 만들었습니다. 큰 가족은 생존에 영향을 미칠 수 있습니다(가족이 있을 경우 생존에 도움 혹은 장애 요인이 될 수 있음). 승객 등급(Pclass)은 숫자형이지만 범주형으로 처리하여 비선형적인 등급 간 차이를 반영했습니다. 이름(Name), 티켓(Ticket), 승객 ID(PassengerId)는 예측에 직접적 가치가 적어 제거했습니다.

- **범주형 변수 인코딩**: 성별(Sex)은 남성 0, 여성 1로 바이너리 인코딩했고, Embarked(C/Q/S)와 Pclass(1/2/3)는 원-핫 인코딩을 적용했습니다. 중복 정보를 피하기 위해 각각 하나의 더미 변수를 기준으로 삼아 한 범주는 제거했습니다. 예를 들어 Embarked는 C를 기준으로 두 개의 더미 컬럼(Q, S)을 남기고, Pclass는 1을 기준으로 두 개의 더미 컬럼(2, 3)을 남겼습니다.

- 이 과정을 거쳐 최종 특성 집합은 다음과 같습니다: Sex, Age, Fare, FamilySize, HasCabin, Pclass_2, Pclass_3, Embarked_Q, Embarked_S. 일부 모델(예: 신경망)에서는 Age와 Fare 등의 수치형 특성을 표준화하여 학습 안정성을 높였습니다. 이후 데이터를 80% 훈련 세트와 20% 테스트 세트로 분할해 미지의 데이터에 대한 성능을 평가했습니다.
![image](https://github.com/user-attachments/assets/80704c46-bceb-4088-a4a9-d3b47364747e)




## 모델 학습 및 비교

생존 예측을 이진 분류 문제로 다뤘으며, 단순 모델부터 복잡한 모델까지 여러 가지를 훈련해 성능을 비교했습니다:

### 기본 모델:

- **로지스틱 회귀**: 특성의 선형 조합으로 생존 확률의 로그 오즈를 예측하는 선형 모델입니다. L2 규제를 사용했고 수렴을 위해 최대 반복 횟수를 늘렸습니다.

- **의사결정 나무**: 데이터 특성 기준으로 분할하는 간단한 나무 모델입니다. 가지치기 없이 최대 깊이로 학습시켜 훈련 데이터에 최대한 적합하도록 했으며, 비선형 관계 포착에 유리합니다.

### 향상된 모델:

- **랜덤 포레스트**: 다수의 결정 트리를 부트스트랩 샘플과 랜덤한 특성 하위 집합으로 학습한 앙상블 모델입니다. 다수의 트리 예측을 집계해 과적합을 줄이고 일반화 성능을 높입니다.

- **XGBoost (극한 그래디언트 부스팅)**: 이전 트리의 오차를 순차적으로 보완하는 그래디언트 부스팅 모델입니다. 기본 파라미터로 100개의 트리를 사용했고, 정규화와 결측값 처리를 효율적으로 수행합니다.

- **신경망 (MLP)**: 두 개의 은닉층(각각 16, 8 뉴런, ReLU 활성화)으로 구성된 단순 피드포워드 다층 퍼셉트론입니다. 출력층은 시그모이드 활성화로 생존 확률을 출력하며, Adam 최적화 및 이진 교차 엔트로피 손실을 사용했습니다. 데이터가 적어 조기 종료(Early Stopping)를 활용해 과적합을 방지했습니다.

훈련은 훈련 데이터로 수행하고, 별도의 테스트 세트로 성능을 평가했습니다. 하이퍼파라미터 튜닝이나 교차검증은 수행하지 않았으며, 기본 설정으로 실험했습니다. 로지스틱 회귀와 신경망은 특성 스케일링이 필요했고, 트리 기반 모델은 스케일링 없이도 잘 작동했습니다.



## 모델 평가

모든 모델은 동일한 테스트 세트에서 다음 지표로 평가했습니다: 정확도(Accuracy), F1 점수(F1 Score), ROC-AUC. 각각 전체 정확성, 양성 클래스(생존)에서 정밀도와 재현율 균형, 분류 임계값에 무관한 판별 능력을 나타냅니다.

| 모델                | 정확도  | F1 점수 | ROC-AUC |
|---------------------|-------|-------|---------|
| 로지스틱 회귀         | 0.80  | 0.73  | 0.83    |
| 의사결정 나무         | 0.80  | 0.73  | 0.77    |
| 랜덤 포레스트         | 0.82  | 0.76  | 0.84    |
| XGBoost             | 0.80  | 0.71  | 0.84    |
| 신경망 (MLP)         | 0.78  | 0.70  | 0.83    |


- 기본 로지스틱 회귀가 테스트에서 약 80% 정확도를 보여주었으며, 의사결정 나무와 거의 동일한 결과를 냈습니다. 의사결정 나무는 생존자 분류 순위가 덜 세밀해 ROC-AUC가 낮았습니다(0.77).

- 향상된 모델 중 랜덤 포레스트가 정확도 82%, F1 0.76, AUC 0.84로 가장 우수했습니다. 앙상블로 과적합을 줄이고 견고한 패턴을 포착했습니다.

- XGBoost도 AUC 0.84로 랜덤 포레스트와 비슷했으나, 기본 파라미터로 학습해 정확도와 F1 점수는 다소 낮았습니다. 튜닝하면 더 좋아질 가능성이 큽니다.

- 신경망은 78% 정확도, F1 0.70, AUC 0.83으로 간단 모델과 비슷했으나 데이터 적음과 복잡성으로 인해 최고 성능은 내지 못했습니다.



## 혼동 행렬 분석

각 모델의 테스트 세트 혼동 행렬에서는 대부분 음성 클래스(사망자)를 정확히 분류했습니다. 로지스틱 회귀와 의사결정 나무는 생존자를 사망자로 잘못 분류한 사례가 21건, 사망자를 생존자로 잘못 분류한 사례가 14건 있었습니다. 랜덤 포레스트는 생존자 오분류(false negative)를 17건으로 줄이고, 다소 더 많은 거짓 양성(15건)을 허용하며 생존자 탐지를 늘렸습니다(52명 vs 48명).

XGBoost는 생존자 44명만 정확히 예측했고 25명을 놓쳤으며, 신경망은 45명 정확히 예측, 24명 놓쳤습니다. 이는 F1 점수 차이와 일치합니다. 랜덤 포레스트는 생존자 탐지를 중시할 때 허용할 수 있는 거짓 양성 증가를 감수해 더 좋은 재현율을 보였습니다.

![image](https://github.com/user-attachments/assets/cafc5c76-dc98-45ed-9456-9db532eb453c)


## ROC 곡선

ROC 곡선은 모든 임계값에서의 참 양성 비율과 거짓 양성 비율의 관계를 나타냅니다. 완벽한 분리는 좌상단(참 양성 1, 거짓 양성 0)으로 표현됩니다. 검은 점선은 무작위 추측 기준선(AUC=0.5)입니다.

랜덤 포레스트와 XGBoost(분홍색, 빨간색 선)가 가장 높은 곡선을 기록했고(AUC 약 0.84), 로지스틱 회귀와 신경망(노란색, 파란색 선)은 근접한 AUC 0.83 수준입니다. 의사결정 나무(주황색 선)는 가장 낮은 AUC 0.77을 기록했습니다.

이 곡선들은 앙상블 모델이 생존자 구분 능력이 약간 우위임을 보여주며, 간단한 로지스틱 회귀도 매우 경쟁력 있음을 시사합니다.

![image](https://github.com/user-attachments/assets/0c044f3d-1334-43d6-a43f-2235f170ac21)
![image](https://github.com/user-attachments/assets/89a0510e-8425-4939-9841-4dd7b6ffc922)
![image](https://github.com/user-attachments/assets/973ded00-e91c-4c56-bed8-0fa251c3202c)
![image](https://github.com/user-attachments/assets/aeb1373b-ad40-4129-a936-d68370f68e81)
![image](https://github.com/user-attachments/assets/33be0eec-bae2-4d7c-8dd7-de1ef04ca18b)

## 특성 중요도

트리 기반 모델에서 특성 중요도를 분석하면 생존 예측에 가장 큰 영향을 준 특징을 알 수 있습니다:

- **Sex (성별)**: 가장 중요한 특성으로, 여성 승객이 훨씬 높은 생존율을 보인 역사적 사실과 일치합니다.

- **Fare (요금)**: 높은 요금을 낸 승객(주로 1등석)이 더 좋은 환경과 구명정 접근성을 가져 생존 가능성이 높았습니다.

- **Age (나이)**: 어린 승객이 우선 구조 대상이었고, 나이가 많을수록 생존 가능성이 낮았습니다.

- 이후 FamilySize와 HasCabin이 중요하지만 상대적으로 낮은 기여도를 보였습니다. 큰 가족은 모두가 구조되기 어려워 생존에 부정적 영향을 미칠 수 있습니다. HasCabin은 등급과 연관 있어 간접적 영향이 있습니다.

- Pclass와 Embarked 더미 변수는 중요도가 낮은데, Fare와 같은 변수들이 이 정보를 대체하기 때문입니다.

XGBoost에서도 동일한 특성 중요도 패턴이 나타나 일관된 인사이트를 제공합니다.



## 결론

본 분석에서는 여러 모델을 통해 타이타닉 승객 생존 예측을 시도했습니다. 결측값 처리, 범주형 인코딩, 가족 규모 생성 등의 전처리 덕분에 간단한 모델도 좋은 성능을 냈습니다.

앙상블 모델인 랜덤 포레스트와 XGBoost가 82% 정확도, AUC 0.84로 가장 뛰어났으며, 기본 로지스틱 회귀(80% 정확도)와 의사결정 나무보다 우수했습니다. 신경망은 제한된 데이터와 간단 특성 때문에 트리 앙상블을 넘지 못했습니다.

모든 모델이 공통적으로 생존에 큰 영향을 준 변수는 성별(여성), 나이(어린이), 그리고 사회적 지위를 나타내는 요금과 객실 보유 여부였습니다. 이는 타이타닉 역사적 사건과 부합하는 중요한 발견입니다.

이 사례는 기초적인 머신러닝 모델이 도메인 지식과 일치하는 패턴을 효과적으로 찾아낼 수 있음을 보여주며, 복잡한 모델이 약간의 성능 향상을 가져오지만 해석 가능성과 특징 중요도를 함께 고려하는 것이 중요함을 시사합니다.
